{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aad5e6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "083be2e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>An Australian police officer has been charged ...</td>\n",
       "      <td>australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Three people have been killed in an auto shop ...</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The trial in the assault and harassment case a...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Soccer is set to trial sin bins at the higher ...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bob Iger, neatly dressed in a gray suit and pr...</td>\n",
       "      <td>media</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7726</th>\n",
       "      <td>Chicago police issued a community alert warnin...</td>\n",
       "      <td>breaking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7727</th>\n",
       "      <td>December is the most important month of the ye...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7728</th>\n",
       "      <td>Earlier this month, Asiaha Butler went to four...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7729</th>\n",
       "      <td>Chicago Ald. Daniel Solis was a newly minted F...</td>\n",
       "      <td>criminal-justice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7730</th>\n",
       "      <td>The FBI is offering $1,000 in reward money for...</td>\n",
       "      <td>breaking</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7731 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text          Category\n",
       "0     An Australian police officer has been charged ...         australia\n",
       "1     Three people have been killed in an auto shop ...                us\n",
       "2     The trial in the assault and harassment case a...     entertainment\n",
       "3     Soccer is set to trial sin bins at the higher ...             sport\n",
       "4     Bob Iger, neatly dressed in a gray suit and pr...             media\n",
       "...                                                 ...               ...\n",
       "7726  Chicago police issued a community alert warnin...          breaking\n",
       "7727  December is the most important month of the ye...          business\n",
       "7728  Earlier this month, Asiaha Butler went to four...          business\n",
       "7729  Chicago Ald. Daniel Solis was a newly minted F...  criminal-justice\n",
       "7730  The FBI is offering $1,000 in reward money for...          breaking\n",
       "\n",
       "[7731 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"cat_train.csv\")\n",
    "df = df.drop(\"Unnamed: 0\", axis=1)\n",
    "df2 = pd.read_csv(\"articles-thursday.csv\")\n",
    "df2 = df2[[\"Text\", \"Category\"]]\n",
    "df = pd.concat([df, df2], ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29f74b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['australia', 'us', 'entertainment', 'sport', 'media', 'style',\n",
       "       'investing', 'world', 'politics', 'americas', 'climate',\n",
       "       'middleeast', 'business', 'health', 'travel', 'cnn10', 'wbd',\n",
       "       'africa', 'opinions', 'tech', 'economy', 'success', 'asia',\n",
       "       'Sports', 'family', 'International', 'The Fifty', 'New York',\n",
       "       'Congress', 'Politics', 'Technology', 'EDUCATION', 'books',\n",
       "       'wellness', 'nation', 'dc-md-va', 'climate-environment', 'sports',\n",
       "       'technology', 'transportation', 'home', 'parenting',\n",
       "       'national-security', 'advice', 'climate-solutions', 'obituaries',\n",
       "       'science', 'briefing', 'symone', 'opinion', 'breakingviews',\n",
       "       'markets', 'fact-check', 'money', 'cruise ship', 'life expectancy',\n",
       "       'COP28', 'Israel Hamas War', 'pediatric', 'retail theft',\n",
       "       'Hart Island', 'haley', 'voting stories', 'Osprey', 'Ukraine',\n",
       "       'Miriam Adelson', 'rosalynn carter', 'financial crimes',\n",
       "       'charlie munger', 'John Cale', 'cop23',\n",
       "       'sexual assault allegations', 'artificial intelligence',\n",
       "       'Gov. Ron DeSantis', 'criminal-justice', 'breaking',\n",
       "       'ct-hinsdale-south-basketball-lawsuit-20231128-ob4kgr5fjvcgfe37acccrduh3q-story.html',\n",
       "       'ct-red-covered-bridge-damaged-princeton-20231128-o52si3osjndzfhzgim5p55ul34-story.html',\n",
       "       'suburbs', 'culture', 'US', 'news', 'living', 'Entertainment',\n",
       "       'Health', 'food', 'News', 'GMA', 'Business', 'china', 'europe',\n",
       "       'uk', 'migrants-thanksgiving-new-york-city',\n",
       "       'nyc-hamas-hate-crime-arrest',\n",
       "       'jonathan-lewis-beating-death-ninth-suspect-arrested', 'homes',\n",
       "       'weather', 'india', 'minnesota-overdue-library-book-100-years',\n",
       "       '2022', '2020', 'cars', 'sag-aftra-deal-terms',\n",
       "       'veterans-day-open-closed-friday-saturday', 'app-sport-section',\n",
       "       'us-park-police-shooting-court-appearance', 'energy', 'live-news',\n",
       "       'lifestyle', 'buisness', 'New Jersey', 'Legal', 'history',\n",
       "       'education', 'immigration', 'arts', 'nyregion', 'sustainability',\n",
       "       'legal', 'life', 'Centers for Medicare & Medicaid Services',\n",
       "       'decongestants', 'Irish music', 'model minority',\n",
       "       'affordable housing', 'Hurricane Idalia', 'cybertruck', 'U.S.',\n",
       "       'Flint water crisis', 'None', 'president biden',\n",
       "       \"De Winton's golden mole\", 'obituary', 'SEC', '90s', 'Apple TV',\n",
       "       'Justice Department', 'environment'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "df[\"Category\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02e52c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Category\"] = df[\"Category\"].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f06496aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_categories(x):\n",
    "    category_mapping = {\n",
    "        'International News': ['world',\"ukraine\", 'australia','india', 'china', 'americas', 'middleeast','international','Israel Hamas War', 'africa', 'asia', 'europe'],\n",
    "        'Politics': ['nation' , 'new york', 'Congress','us', 'politics'],\n",
    "        'Business and Economy': ['investing', 'business', 'markets', 'money'],\n",
    "        'Entertainment and Lifestyle': [\"lifestyle\",\"travel\", 'entertainment', 'cars', 'culture', 'food', 'style', 'tech','advice', 'success', 'books', 'cruise ship', 'wellness', 'family', 'life expectancy'],\n",
    "        'Climate and Environment': ['climate','energy' 'climate-environment', 'climate-solutions'],\n",
    "        'Health | Science | Technology': ['health', 'science', 'technology', 'artificial intelligence'],\n",
    "        'Sports': ['sport', 'sports'],\n",
    "        'Law and Justice': ['national-security', 'criminajustice', \"retail theft\", \"financial crimes\", \"crime\",  ],\n",
    "        'del' : [\"weather\" ] \n",
    "    }\n",
    "\n",
    "    categorized_result = {category: [] for category in category_mapping.keys()}\n",
    "    matched_category = None\n",
    "    for main_category, sub_categories in category_mapping.items():\n",
    "        if any(sub_category in x.lower() for sub_category in sub_categories):\n",
    "            matched_category = main_category\n",
    "            break\n",
    "    \n",
    "    return matched_category\n",
    "\n",
    "df[\"cat_label\"] = df[\"Category\"].apply(categorize_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e0be306",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jacob\\AppData\\Local\\Temp\\ipykernel_19496\\3437563882.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.dropna(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df = df[df[\"cat_label\"]!=\"del\"]\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02c3e99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jacob\\AppData\\Local\\Temp\\ipykernel_19496\\3277185638.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop_duplicates(keep=\"first\", inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "      <th>cat_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>An Australian police officer has been charged ...</td>\n",
       "      <td>australia</td>\n",
       "      <td>International News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Three people have been killed in an auto shop ...</td>\n",
       "      <td>us</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The trial in the assault and harassment case a...</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>Entertainment and Lifestyle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Soccer is set to trial sin bins at the higher ...</td>\n",
       "      <td>sport</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>“I never really paid attention to politics bef...</td>\n",
       "      <td>style</td>\n",
       "      <td>Entertainment and Lifestyle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7720</th>\n",
       "      <td>The Clybourn Corridor shopping district may be...</td>\n",
       "      <td>business</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7722</th>\n",
       "      <td>Cook County prosecutors charged two men Tuesda...</td>\n",
       "      <td>criminal-justice</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7723</th>\n",
       "      <td>General Motors says pretax earnings took a $1....</td>\n",
       "      <td>business</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7724</th>\n",
       "      <td>“The Shark” has been beached.Two months after ...</td>\n",
       "      <td>criminal-justice</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7728</th>\n",
       "      <td>Earlier this month, Asiaha Butler went to four...</td>\n",
       "      <td>business</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3165 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text          Category  \\\n",
       "0     An Australian police officer has been charged ...         australia   \n",
       "1     Three people have been killed in an auto shop ...                us   \n",
       "2     The trial in the assault and harassment case a...     entertainment   \n",
       "3     Soccer is set to trial sin bins at the higher ...             sport   \n",
       "5     “I never really paid attention to politics bef...             style   \n",
       "...                                                 ...               ...   \n",
       "7720  The Clybourn Corridor shopping district may be...          business   \n",
       "7722  Cook County prosecutors charged two men Tuesda...  criminal-justice   \n",
       "7723  General Motors says pretax earnings took a $1....          business   \n",
       "7724  “The Shark” has been beached.Two months after ...  criminal-justice   \n",
       "7728  Earlier this month, Asiaha Butler went to four...          business   \n",
       "\n",
       "                        cat_label  \n",
       "0              International News  \n",
       "1                        Politics  \n",
       "2     Entertainment and Lifestyle  \n",
       "3                          Sports  \n",
       "5     Entertainment and Lifestyle  \n",
       "...                           ...  \n",
       "7720                     Politics  \n",
       "7722                     Politics  \n",
       "7723                     Politics  \n",
       "7724                     Politics  \n",
       "7728                     Politics  \n",
       "\n",
       "[3165 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(keep=\"first\", inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "142c2ebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Politics                         1621\n",
       "Entertainment and Lifestyle       665\n",
       "International News                364\n",
       "Sports                            347\n",
       "Health | Science | Technology     108\n",
       "Business and Economy               40\n",
       "Climate and Environment            17\n",
       "Law and Justice                     3\n",
       "Name: cat_label, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"cat_label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c2946b",
   "metadata": {},
   "source": [
    "## Tokenize etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ecd437d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk #Natural Language tool kit -- this pacakge is quite a mess. Was poorly design and the documentation is not great\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7665cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jacob\\AppData\\Local\\Temp\\ipykernel_19496\\3454624885.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['tokenized'] = df.apply(tokenizer_and_remove_punctuation,axis=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "      <th>cat_label</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>An Australian police officer has been charged ...</td>\n",
       "      <td>australia</td>\n",
       "      <td>International News</td>\n",
       "      <td>[an, australian, police, officer, has, been, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Three people have been killed in an auto shop ...</td>\n",
       "      <td>us</td>\n",
       "      <td>Politics</td>\n",
       "      <td>[three, people, have, been, killed, in, an, au...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The trial in the assault and harassment case a...</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>Entertainment and Lifestyle</td>\n",
       "      <td>[the, trial, in, the, assault, and, harassment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Soccer is set to trial sin bins at the higher ...</td>\n",
       "      <td>sport</td>\n",
       "      <td>Sports</td>\n",
       "      <td>[soccer, is, set, to, trial, sin, bins, at, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>“I never really paid attention to politics bef...</td>\n",
       "      <td>style</td>\n",
       "      <td>Entertainment and Lifestyle</td>\n",
       "      <td>[i, never, really, paid, attention, to, politi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text       Category  \\\n",
       "0  An Australian police officer has been charged ...      australia   \n",
       "1  Three people have been killed in an auto shop ...             us   \n",
       "2  The trial in the assault and harassment case a...  entertainment   \n",
       "3  Soccer is set to trial sin bins at the higher ...          sport   \n",
       "5  “I never really paid attention to politics bef...          style   \n",
       "\n",
       "                     cat_label  \\\n",
       "0           International News   \n",
       "1                     Politics   \n",
       "2  Entertainment and Lifestyle   \n",
       "3                       Sports   \n",
       "5  Entertainment and Lifestyle   \n",
       "\n",
       "                                           tokenized  \n",
       "0  [an, australian, police, officer, has, been, c...  \n",
       "1  [three, people, have, been, killed, in, an, au...  \n",
       "2  [the, trial, in, the, assault, and, harassment...  \n",
       "3  [soccer, is, set, to, trial, sin, bins, at, th...  \n",
       "5  [i, never, really, paid, attention, to, politi...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenizer_and_remove_punctuation(row):\n",
    "    tokens = word_tokenize(row['Text'])\n",
    "    return [word.lower() for word in tokens if word.isalpha()]\n",
    "\n",
    "df['tokenized'] = df.apply(tokenizer_and_remove_punctuation,axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6609950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word], lang='eng')[0][1][0].upper() # gets first letter of POS categorization\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1453ef70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jacob\\AppData\\Local\\Temp\\ipykernel_19496\\3874560291.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['lemmatized'] = df.apply(lemmatizer_with_pos,axis=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "      <th>cat_label</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>An Australian police officer has been charged ...</td>\n",
       "      <td>australia</td>\n",
       "      <td>International News</td>\n",
       "      <td>[an, australian, police, officer, has, been, c...</td>\n",
       "      <td>[an, australian, police, officer, have, be, ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Three people have been killed in an auto shop ...</td>\n",
       "      <td>us</td>\n",
       "      <td>Politics</td>\n",
       "      <td>[three, people, have, been, killed, in, an, au...</td>\n",
       "      <td>[three, people, have, be, kill, in, an, auto, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The trial in the assault and harassment case a...</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>Entertainment and Lifestyle</td>\n",
       "      <td>[the, trial, in, the, assault, and, harassment...</td>\n",
       "      <td>[the, trial, in, the, assault, and, harassment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Soccer is set to trial sin bins at the higher ...</td>\n",
       "      <td>sport</td>\n",
       "      <td>Sports</td>\n",
       "      <td>[soccer, is, set, to, trial, sin, bins, at, th...</td>\n",
       "      <td>[soccer, be, set, to, trial, sin, bin, at, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>“I never really paid attention to politics bef...</td>\n",
       "      <td>style</td>\n",
       "      <td>Entertainment and Lifestyle</td>\n",
       "      <td>[i, never, really, paid, attention, to, politi...</td>\n",
       "      <td>[i, never, really, paid, attention, to, politi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text       Category  \\\n",
       "0  An Australian police officer has been charged ...      australia   \n",
       "1  Three people have been killed in an auto shop ...             us   \n",
       "2  The trial in the assault and harassment case a...  entertainment   \n",
       "3  Soccer is set to trial sin bins at the higher ...          sport   \n",
       "5  “I never really paid attention to politics bef...          style   \n",
       "\n",
       "                     cat_label  \\\n",
       "0           International News   \n",
       "1                     Politics   \n",
       "2  Entertainment and Lifestyle   \n",
       "3                       Sports   \n",
       "5  Entertainment and Lifestyle   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  [an, australian, police, officer, has, been, c...   \n",
       "1  [three, people, have, been, killed, in, an, au...   \n",
       "2  [the, trial, in, the, assault, and, harassment...   \n",
       "3  [soccer, is, set, to, trial, sin, bins, at, th...   \n",
       "5  [i, never, really, paid, attention, to, politi...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  [an, australian, police, officer, have, be, ch...  \n",
       "1  [three, people, have, be, kill, in, an, auto, ...  \n",
       "2  [the, trial, in, the, assault, and, harassment...  \n",
       "3  [soccer, be, set, to, trial, sin, bin, at, the...  \n",
       "5  [i, never, really, paid, attention, to, politi...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lemmatizer_with_pos(row):\n",
    "      return [lemmatizer.lemmatize(word,get_wordnet_pos(word)) for word in row['tokenized']]\n",
    "\n",
    "df['lemmatized'] = df.apply(lemmatizer_with_pos,axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72b01c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jacob\\AppData\\Local\\Temp\\ipykernel_19496\\3986828676.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['no_stopwords'] = df.apply(remove_sw,axis=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "      <th>cat_label</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>no_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>An Australian police officer has been charged ...</td>\n",
       "      <td>australia</td>\n",
       "      <td>International News</td>\n",
       "      <td>[an, australian, police, officer, has, been, c...</td>\n",
       "      <td>[an, australian, police, officer, have, be, ch...</td>\n",
       "      <td>[grievous, meter, affiliate, pound, offense, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Three people have been killed in an auto shop ...</td>\n",
       "      <td>us</td>\n",
       "      <td>Politics</td>\n",
       "      <td>[three, people, have, been, killed, in, an, au...</td>\n",
       "      <td>[three, people, have, be, kill, in, an, auto, ...</td>\n",
       "      <td>[joint, person, affiliate, investigate, house,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The trial in the assault and harassment case a...</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>Entertainment and Lifestyle</td>\n",
       "      <td>[the, trial, in, the, assault, and, harassment...</td>\n",
       "      <td>[the, trial, in, the, assault, and, harassment...</td>\n",
       "      <td>[city, series, kang, laceration, jonathan, beg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Soccer is set to trial sin bins at the higher ...</td>\n",
       "      <td>sport</td>\n",
       "      <td>Sports</td>\n",
       "      <td>[soccer, is, set, to, trial, sin, bins, at, th...</td>\n",
       "      <td>[soccer, be, set, to, trial, sin, bin, at, the...</td>\n",
       "      <td>[terry, great, point, international, controver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>“I never really paid attention to politics bef...</td>\n",
       "      <td>style</td>\n",
       "      <td>Entertainment and Lifestyle</td>\n",
       "      <td>[i, never, really, paid, attention, to, politi...</td>\n",
       "      <td>[i, never, really, paid, attention, to, politi...</td>\n",
       "      <td>[despite, native, dance, harder, series, elect...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text       Category  \\\n",
       "0  An Australian police officer has been charged ...      australia   \n",
       "1  Three people have been killed in an auto shop ...             us   \n",
       "2  The trial in the assault and harassment case a...  entertainment   \n",
       "3  Soccer is set to trial sin bins at the higher ...          sport   \n",
       "5  “I never really paid attention to politics bef...          style   \n",
       "\n",
       "                     cat_label  \\\n",
       "0           International News   \n",
       "1                     Politics   \n",
       "2  Entertainment and Lifestyle   \n",
       "3                       Sports   \n",
       "5  Entertainment and Lifestyle   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  [an, australian, police, officer, has, been, c...   \n",
       "1  [three, people, have, been, killed, in, an, au...   \n",
       "2  [the, trial, in, the, assault, and, harassment...   \n",
       "3  [soccer, is, set, to, trial, sin, bins, at, th...   \n",
       "5  [i, never, really, paid, attention, to, politi...   \n",
       "\n",
       "                                          lemmatized  \\\n",
       "0  [an, australian, police, officer, have, be, ch...   \n",
       "1  [three, people, have, be, kill, in, an, auto, ...   \n",
       "2  [the, trial, in, the, assault, and, harassment...   \n",
       "3  [soccer, be, set, to, trial, sin, bin, at, the...   \n",
       "5  [i, never, really, paid, attention, to, politi...   \n",
       "\n",
       "                                        no_stopwords  \n",
       "0  [grievous, meter, affiliate, pound, offense, g...  \n",
       "1  [joint, person, affiliate, investigate, house,...  \n",
       "2  [city, series, kang, laceration, jonathan, beg...  \n",
       "3  [terry, great, point, international, controver...  \n",
       "5  [despite, native, dance, harder, series, elect...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove stopwords\n",
    "\n",
    "def remove_sw(row):\n",
    "      return list(set(row['lemmatized']).difference(stopwords.words()))\n",
    "\n",
    "df['no_stopwords'] = df.apply(remove_sw,axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e78699d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jacob\\AppData\\Local\\Temp\\ipykernel_19496\\1045496448.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['clean_blob'] = df.apply(re_blob,axis=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "      <th>cat_label</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>no_stopwords</th>\n",
       "      <th>clean_blob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>An Australian police officer has been charged ...</td>\n",
       "      <td>australia</td>\n",
       "      <td>International News</td>\n",
       "      <td>[an, australian, police, officer, has, been, c...</td>\n",
       "      <td>[an, australian, police, officer, have, be, ch...</td>\n",
       "      <td>[grievous, meter, affiliate, pound, offense, g...</td>\n",
       "      <td>grievous meter affiliate pound offense grab fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Three people have been killed in an auto shop ...</td>\n",
       "      <td>us</td>\n",
       "      <td>Politics</td>\n",
       "      <td>[three, people, have, been, killed, in, an, au...</td>\n",
       "      <td>[three, people, have, be, kill, in, an, auto, ...</td>\n",
       "      <td>[joint, person, affiliate, investigate, house,...</td>\n",
       "      <td>joint person affiliate investigate house kill ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The trial in the assault and harassment case a...</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>Entertainment and Lifestyle</td>\n",
       "      <td>[the, trial, in, the, assault, and, harassment...</td>\n",
       "      <td>[the, trial, in, the, assault, and, harassment...</td>\n",
       "      <td>[city, series, kang, laceration, jonathan, beg...</td>\n",
       "      <td>city series kang laceration jonathan begin vil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Soccer is set to trial sin bins at the higher ...</td>\n",
       "      <td>sport</td>\n",
       "      <td>Sports</td>\n",
       "      <td>[soccer, is, set, to, trial, sin, bins, at, th...</td>\n",
       "      <td>[soccer, be, set, to, trial, sin, bin, at, the...</td>\n",
       "      <td>[terry, great, point, international, controver...</td>\n",
       "      <td>terry great point international controversy fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>“I never really paid attention to politics bef...</td>\n",
       "      <td>style</td>\n",
       "      <td>Entertainment and Lifestyle</td>\n",
       "      <td>[i, never, really, paid, attention, to, politi...</td>\n",
       "      <td>[i, never, really, paid, attention, to, politi...</td>\n",
       "      <td>[despite, native, dance, harder, series, elect...</td>\n",
       "      <td>despite native dance harder series election st...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text       Category  \\\n",
       "0  An Australian police officer has been charged ...      australia   \n",
       "1  Three people have been killed in an auto shop ...             us   \n",
       "2  The trial in the assault and harassment case a...  entertainment   \n",
       "3  Soccer is set to trial sin bins at the higher ...          sport   \n",
       "5  “I never really paid attention to politics bef...          style   \n",
       "\n",
       "                     cat_label  \\\n",
       "0           International News   \n",
       "1                     Politics   \n",
       "2  Entertainment and Lifestyle   \n",
       "3                       Sports   \n",
       "5  Entertainment and Lifestyle   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  [an, australian, police, officer, has, been, c...   \n",
       "1  [three, people, have, been, killed, in, an, au...   \n",
       "2  [the, trial, in, the, assault, and, harassment...   \n",
       "3  [soccer, is, set, to, trial, sin, bins, at, th...   \n",
       "5  [i, never, really, paid, attention, to, politi...   \n",
       "\n",
       "                                          lemmatized  \\\n",
       "0  [an, australian, police, officer, have, be, ch...   \n",
       "1  [three, people, have, be, kill, in, an, auto, ...   \n",
       "2  [the, trial, in, the, assault, and, harassment...   \n",
       "3  [soccer, be, set, to, trial, sin, bin, at, the...   \n",
       "5  [i, never, really, paid, attention, to, politi...   \n",
       "\n",
       "                                        no_stopwords  \\\n",
       "0  [grievous, meter, affiliate, pound, offense, g...   \n",
       "1  [joint, person, affiliate, investigate, house,...   \n",
       "2  [city, series, kang, laceration, jonathan, beg...   \n",
       "3  [terry, great, point, international, controver...   \n",
       "5  [despite, native, dance, harder, series, elect...   \n",
       "\n",
       "                                          clean_blob  \n",
       "0  grievous meter affiliate pound offense grab fr...  \n",
       "1  joint person affiliate investigate house kill ...  \n",
       "2  city series kang laceration jonathan begin vil...  \n",
       "3  terry great point international controversy fa...  \n",
       "5  despite native dance harder series election st...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def re_blob(row):\n",
    "      return \" \".join(row['no_stopwords'])\n",
    "\n",
    "df['clean_blob'] = df.apply(re_blob,axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "14affa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_vect = CountVectorizer(max_features=7500)\n",
    "# fit creates one entry for each different word seen\n",
    "X = bow_vect.fit_transform(df['clean_blob']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "9116b6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('bow_vect.pkl', 'wb') as file:\n",
    "    pickle.dump(bow_vect, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1dd6d76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"cat_label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "704ba3bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.model_selection import train_test_split\\nimport pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a776e5e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Politics                         1301\n",
       "Entertainment and Lifestyle       527\n",
       "Sports                            290\n",
       "International News                285\n",
       "Health | Science | Technology      85\n",
       "Business and Economy               29\n",
       "Climate and Environment            13\n",
       "Law and Justice                     2\n",
       "Name: cat_label, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6d79b977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.linear_model import LogisticRegression\\nfrom sklearn.model_selection import train_test_split\\nimport pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train = pd.DataFrame(X_train)\n",
    "y_train = y_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "50941f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.linear_model import LogisticRegression\\nfrom sklearn.model_selection import train_test_split\\nimport pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.linear_model import LogisticRegression\\nfrom sklearn.model_selection import train_test_split\\nimport pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "politics = train[train[\"cat_label\"]==\"Politics\"]\n",
    "not_politics = train[train[\"cat_label\"]!=\"Politics\"]\n",
    "\n",
    "politics_under = resample(politics,\n",
    "                   replace=False,\n",
    "                   n_samples=800,\n",
    "                    random_state=0)\n",
    "\n",
    "train_under = pd.concat([politics_under, not_politics])\n",
    "X_train_under = train_under.drop(\"cat_label\", axis=1)\n",
    "y_train_under = train_under[\"cat_label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "df84de91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Politics                         800\n",
       "Entertainment and Lifestyle      527\n",
       "Sports                           290\n",
       "International News               285\n",
       "Health | Science | Technology     85\n",
       "Business and Economy              29\n",
       "Climate and Environment           13\n",
       "Law and Justice                    2\n",
       "Name: cat_label, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_under.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "29351a42",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m best_model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m      2\u001b[0m y_pred\u001b[38;5;241m=\u001b[39m best_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_model' is not defined"
     ]
    }
   ],
   "source": [
    "best_model.fit(X_train, y_train)\n",
    "y_pred= best_model.predict(X_test)\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "#print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "6d5202e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('cat_model.pkl', 'wb') as file:\n",
    "    pickle.dump(best_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9500523b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.linear_model import LogisticRegression\\nfrom sklearn.model_selection import train_test_split\\nimport pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8593996840442338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "log = LogisticRegression()\n",
    "\n",
    "log.fit(X_train_under, y_train_under)\n",
    "y_pred = log.predict(X_test)\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "#print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bfbd2f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8120063191153238\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC()\n",
    "\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred = svc.predict(X_test)\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "#print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6017d602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7740916271721959\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "#print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ab8bb2c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.linear_model import LogisticRegression\\nfrom sklearn.model_selection import train_test_split\\nimport pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "90 fits failed out of a total of 240.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.0114531         nan 0.70773752 0.70734305\n",
      " 0.6927279  0.70734305        nan        nan 0.51382386        nan\n",
      " 0.83214834 0.83175309 0.83175386 0.83214834        nan        nan\n",
      " 0.80648861        nan 0.8534813  0.85387656 0.86177156 0.85466629\n",
      "        nan        nan 0.84755245        nan 0.85426948 0.85584894\n",
      " 0.86058579 0.8570316         nan        nan 0.8463659         nan\n",
      " 0.85466006 0.85347584 0.86058735 0.85584817        nan        nan\n",
      " 0.85742529        nan 0.85466006 0.85386876 0.86098105 0.85584661]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Accuracy: 0.85\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "              'penalty': ['l1', 'l2'],\n",
    "              'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag']}\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(logreg, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c067be02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7977883096366508"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d8a77c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
