{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aad5e6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "083be2e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LogisticRegression\\nimport pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>An Australian police officer has been charged ...</td>\n",
       "      <td>australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Three people have been killed in an auto shop ...</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The trial in the assault and harassment case a...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Soccer is set to trial sin bins at the higher ...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bob Iger, neatly dressed in a gray suit and pr...</td>\n",
       "      <td>media</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7383</th>\n",
       "      <td>Kevin McCarthy has for now lost the House spea...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7384</th>\n",
       "      <td>Michael Duane Zack III, who was convicted of t...</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7385</th>\n",
       "      <td>Seven Starbucks locations across San Francisco...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7386</th>\n",
       "      <td>At least 21 people were killed, including two ...</td>\n",
       "      <td>europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7387</th>\n",
       "      <td>Former President Donald Trump spent the last t...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5162 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text       Category\n",
       "0     An Australian police officer has been charged ...      australia\n",
       "1     Three people have been killed in an auto shop ...             us\n",
       "2     The trial in the assault and harassment case a...  entertainment\n",
       "3     Soccer is set to trial sin bins at the higher ...          sport\n",
       "4     Bob Iger, neatly dressed in a gray suit and pr...          media\n",
       "...                                                 ...            ...\n",
       "7383  Kevin McCarthy has for now lost the House spea...       politics\n",
       "7384  Michael Duane Zack III, who was convicted of t...             us\n",
       "7385  Seven Starbucks locations across San Francisco...       business\n",
       "7386  At least 21 people were killed, including two ...         europe\n",
       "7387  Former President Donald Trump spent the last t...       politics\n",
       "\n",
       "[5162 rows x 2 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"cat_train.csv\")\n",
    "df = df.drop(\"Unnamed: 0\", axis=1)\n",
    "df.dropna(inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "09c910b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LogisticRegression\\nimport pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv(\"C:/Users/Jacob/Desktop/Iron Hack/Course/projects/week 9/ironhack-final-project/web app/datasets/all_articles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "29f74b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Politics                         951\n",
       "Entertainment and Lifestyle      346\n",
       "International News               306\n",
       "Sports                           211\n",
       "Business and Economy              45\n",
       "Health | Science | Technology     34\n",
       "Climate and Environment           29\n",
       "Law and Justice                   23\n",
       "Name: cat_label, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna(inplace=True)\n",
    "data = data[data[\"cat_label\"]!= \"Breaking News\"]\n",
    "data[\"cat_label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "02e52c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Category\"] = df[\"Category\"].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f06496aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_categories(x):\n",
    "    category_mapping = {\n",
    "        'International News': ['world',\"ukraine\", 'australia','india', 'china', 'americas', 'middleeast','international','Israel Hamas War', 'africa', 'asia', 'europe'],\n",
    "        'Politics': ['nation' , 'new york', 'Congress','us', 'politics'],\n",
    "        'Business and Economy': ['investing', 'business', 'markets', 'money'],\n",
    "        'Entertainment and Lifestyle': [\"lifestyle\",\"travel\", 'entertainment', 'cars', 'culture', 'food', 'style', 'tech','advice', 'success', 'books', 'cruise ship', 'wellness', 'family', 'life expectancy'],\n",
    "        'Climate and Environment': ['climate','energy' 'climate-environment', 'climate-solutions'],\n",
    "        'Health | Science | Technology': ['health', 'science', 'technology', 'artificial intelligence'],\n",
    "        'Sports': ['sport', 'sports'],\n",
    "        'Law and Justice': ['national-security', 'criminajustice', \"retail theft\", \"financial crimes\", \"crime\",  ],\n",
    "        'del' : [\"weather\" ] \n",
    "    }\n",
    "\n",
    "    categorized_result = {category: [] for category in category_mapping.keys()}\n",
    "    matched_category = None\n",
    "    for main_category, sub_categories in category_mapping.items():\n",
    "        if any(sub_category in x.lower() for sub_category in sub_categories):\n",
    "            matched_category = main_category\n",
    "            break\n",
    "    \n",
    "    return matched_category\n",
    "\n",
    "df[\"cat_label\"] = df[\"Category\"].apply(categorize_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3e0be306",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"cat_label\"]!=\"del\"]\n",
    "df = df[df[\"cat_label\"]!=\"politics\"]\n",
    "df.dropna(inplace=True)\n",
    "df = df[[\"Text\", \"cat_label\"]]\n",
    "df = df[[\"Text\", \"cat_label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "49594d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"Text\", \"cat_label\"]]\n",
    "data = data[[\"Text\", \"cat_label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7486c085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LogisticRegression\\nimport pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.concat([data, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "02c3e99b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>cat_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senate Majority Leader Chuck Schumer accused K...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Panera is being sued again after another custo...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Drug manufacturer Eli Lilly announced Tuesday ...</td>\n",
       "      <td>Health | Science | Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>As director of the Lymphoma Clinical Research ...</td>\n",
       "      <td>Health | Science | Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Democratic Rep. Pramila Jayapal of Washington ...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7383</th>\n",
       "      <td>Kevin McCarthy has for now lost the House spea...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7384</th>\n",
       "      <td>Michael Duane Zack III, who was convicted of t...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7385</th>\n",
       "      <td>Seven Starbucks locations across San Francisco...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7386</th>\n",
       "      <td>At least 21 people were killed, including two ...</td>\n",
       "      <td>International News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7387</th>\n",
       "      <td>Former President Donald Trump spent the last t...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4726 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  \\\n",
       "0     Senate Majority Leader Chuck Schumer accused K...   \n",
       "1     Panera is being sued again after another custo...   \n",
       "2     Drug manufacturer Eli Lilly announced Tuesday ...   \n",
       "3     As director of the Lymphoma Clinical Research ...   \n",
       "4     Democratic Rep. Pramila Jayapal of Washington ...   \n",
       "...                                                 ...   \n",
       "7383  Kevin McCarthy has for now lost the House spea...   \n",
       "7384  Michael Duane Zack III, who was convicted of t...   \n",
       "7385  Seven Starbucks locations across San Francisco...   \n",
       "7386  At least 21 people were killed, including two ...   \n",
       "7387  Former President Donald Trump spent the last t...   \n",
       "\n",
       "                          cat_label  \n",
       "0                          Politics  \n",
       "1                          Politics  \n",
       "2     Health | Science | Technology  \n",
       "3     Health | Science | Technology  \n",
       "4                          Politics  \n",
       "...                             ...  \n",
       "7383                       Politics  \n",
       "7384                       Politics  \n",
       "7385                       Politics  \n",
       "7386             International News  \n",
       "7387                       Politics  \n",
       "\n",
       "[4726 rows x 2 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(keep=\"first\", inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "142c2ebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Politics                         2356\n",
       "Entertainment and Lifestyle      1011\n",
       "International News                603\n",
       "Sports                            499\n",
       "Health | Science | Technology     127\n",
       "Business and Economy               67\n",
       "Climate and Environment            39\n",
       "Law and Justice                    24\n",
       "Name: cat_label, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"cat_label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c2946b",
   "metadata": {},
   "source": [
    "## Tokenize etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1ecd437d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk #Natural Language tool kit -- this pacakge is quite a mess. Was poorly design and the documentation is not great\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c7665cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>cat_label</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senate Majority Leader Chuck Schumer accused K...</td>\n",
       "      <td>Politics</td>\n",
       "      <td>[senate, majority, leader, chuck, schumer, acc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Panera is being sued again after another custo...</td>\n",
       "      <td>Politics</td>\n",
       "      <td>[panera, is, being, sued, again, after, anothe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Drug manufacturer Eli Lilly announced Tuesday ...</td>\n",
       "      <td>Health | Science | Technology</td>\n",
       "      <td>[drug, manufacturer, eli, lilly, announced, tu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>As director of the Lymphoma Clinical Research ...</td>\n",
       "      <td>Health | Science | Technology</td>\n",
       "      <td>[as, director, of, the, lymphoma, clinical, re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Democratic Rep. Pramila Jayapal of Washington ...</td>\n",
       "      <td>Politics</td>\n",
       "      <td>[democratic, pramila, jayapal, of, washington,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  Senate Majority Leader Chuck Schumer accused K...   \n",
       "1  Panera is being sued again after another custo...   \n",
       "2  Drug manufacturer Eli Lilly announced Tuesday ...   \n",
       "3  As director of the Lymphoma Clinical Research ...   \n",
       "4  Democratic Rep. Pramila Jayapal of Washington ...   \n",
       "\n",
       "                       cat_label  \\\n",
       "0                       Politics   \n",
       "1                       Politics   \n",
       "2  Health | Science | Technology   \n",
       "3  Health | Science | Technology   \n",
       "4                       Politics   \n",
       "\n",
       "                                           tokenized  \n",
       "0  [senate, majority, leader, chuck, schumer, acc...  \n",
       "1  [panera, is, being, sued, again, after, anothe...  \n",
       "2  [drug, manufacturer, eli, lilly, announced, tu...  \n",
       "3  [as, director, of, the, lymphoma, clinical, re...  \n",
       "4  [democratic, pramila, jayapal, of, washington,...  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenizer_and_remove_punctuation(row):\n",
    "    tokens = word_tokenize(row['Text'])\n",
    "    return [word.lower() for word in tokens if word.isalpha()]\n",
    "\n",
    "df['tokenized'] = df.apply(tokenizer_and_remove_punctuation,axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d6609950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word], lang='eng')[0][1][0].upper() # gets first letter of POS categorization\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1453ef70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>cat_label</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senate Majority Leader Chuck Schumer accused K...</td>\n",
       "      <td>Politics</td>\n",
       "      <td>[senate, majority, leader, chuck, schumer, acc...</td>\n",
       "      <td>[senate, majority, leader, chuck, schumer, acc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Panera is being sued again after another custo...</td>\n",
       "      <td>Politics</td>\n",
       "      <td>[panera, is, being, sued, again, after, anothe...</td>\n",
       "      <td>[panera, be, be, sue, again, after, another, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Drug manufacturer Eli Lilly announced Tuesday ...</td>\n",
       "      <td>Health | Science | Technology</td>\n",
       "      <td>[drug, manufacturer, eli, lilly, announced, tu...</td>\n",
       "      <td>[drug, manufacturer, eli, lilly, announce, tue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>As director of the Lymphoma Clinical Research ...</td>\n",
       "      <td>Health | Science | Technology</td>\n",
       "      <td>[as, director, of, the, lymphoma, clinical, re...</td>\n",
       "      <td>[a, director, of, the, lymphoma, clinical, res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Democratic Rep. Pramila Jayapal of Washington ...</td>\n",
       "      <td>Politics</td>\n",
       "      <td>[democratic, pramila, jayapal, of, washington,...</td>\n",
       "      <td>[democratic, pramila, jayapal, of, washington,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  Senate Majority Leader Chuck Schumer accused K...   \n",
       "1  Panera is being sued again after another custo...   \n",
       "2  Drug manufacturer Eli Lilly announced Tuesday ...   \n",
       "3  As director of the Lymphoma Clinical Research ...   \n",
       "4  Democratic Rep. Pramila Jayapal of Washington ...   \n",
       "\n",
       "                       cat_label  \\\n",
       "0                       Politics   \n",
       "1                       Politics   \n",
       "2  Health | Science | Technology   \n",
       "3  Health | Science | Technology   \n",
       "4                       Politics   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  [senate, majority, leader, chuck, schumer, acc...   \n",
       "1  [panera, is, being, sued, again, after, anothe...   \n",
       "2  [drug, manufacturer, eli, lilly, announced, tu...   \n",
       "3  [as, director, of, the, lymphoma, clinical, re...   \n",
       "4  [democratic, pramila, jayapal, of, washington,...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  [senate, majority, leader, chuck, schumer, acc...  \n",
       "1  [panera, be, be, sue, again, after, another, c...  \n",
       "2  [drug, manufacturer, eli, lilly, announce, tue...  \n",
       "3  [a, director, of, the, lymphoma, clinical, res...  \n",
       "4  [democratic, pramila, jayapal, of, washington,...  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lemmatizer_with_pos(row):\n",
    "      return [lemmatizer.lemmatize(word,get_wordnet_pos(word)) for word in row['tokenized']]\n",
    "\n",
    "df['lemmatized'] = df.apply(lemmatizer_with_pos,axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "72b01c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>cat_label</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>no_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senate Majority Leader Chuck Schumer accused K...</td>\n",
       "      <td>Politics</td>\n",
       "      <td>[senate, majority, leader, chuck, schumer, acc...</td>\n",
       "      <td>[senate, majority, leader, chuck, schumer, acc...</td>\n",
       "      <td>[world, antisemitism, speech, felt, resolution...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Panera is being sued again after another custo...</td>\n",
       "      <td>Politics</td>\n",
       "      <td>[panera, is, being, sued, again, after, anothe...</td>\n",
       "      <td>[panera, be, be, sue, again, after, another, c...</td>\n",
       "      <td>[content, investigate, limit, population, cour...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Drug manufacturer Eli Lilly announced Tuesday ...</td>\n",
       "      <td>Health | Science | Technology</td>\n",
       "      <td>[drug, manufacturer, eli, lilly, announced, tu...</td>\n",
       "      <td>[drug, manufacturer, eli, lilly, announce, tue...</td>\n",
       "      <td>[active, weight, announce, approve, sleep, rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>As director of the Lymphoma Clinical Research ...</td>\n",
       "      <td>Health | Science | Technology</td>\n",
       "      <td>[as, director, of, the, lymphoma, clinical, re...</td>\n",
       "      <td>[a, director, of, the, lymphoma, clinical, res...</td>\n",
       "      <td>[medicare, recommends, word, investigate, mone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Democratic Rep. Pramila Jayapal of Washington ...</td>\n",
       "      <td>Politics</td>\n",
       "      <td>[democratic, pramila, jayapal, of, washington,...</td>\n",
       "      <td>[democratic, pramila, jayapal, of, washington,...</td>\n",
       "      <td>[world, rape, meaningful, antisemitism, number...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  Senate Majority Leader Chuck Schumer accused K...   \n",
       "1  Panera is being sued again after another custo...   \n",
       "2  Drug manufacturer Eli Lilly announced Tuesday ...   \n",
       "3  As director of the Lymphoma Clinical Research ...   \n",
       "4  Democratic Rep. Pramila Jayapal of Washington ...   \n",
       "\n",
       "                       cat_label  \\\n",
       "0                       Politics   \n",
       "1                       Politics   \n",
       "2  Health | Science | Technology   \n",
       "3  Health | Science | Technology   \n",
       "4                       Politics   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  [senate, majority, leader, chuck, schumer, acc...   \n",
       "1  [panera, is, being, sued, again, after, anothe...   \n",
       "2  [drug, manufacturer, eli, lilly, announced, tu...   \n",
       "3  [as, director, of, the, lymphoma, clinical, re...   \n",
       "4  [democratic, pramila, jayapal, of, washington,...   \n",
       "\n",
       "                                          lemmatized  \\\n",
       "0  [senate, majority, leader, chuck, schumer, acc...   \n",
       "1  [panera, be, be, sue, again, after, another, c...   \n",
       "2  [drug, manufacturer, eli, lilly, announce, tue...   \n",
       "3  [a, director, of, the, lymphoma, clinical, res...   \n",
       "4  [democratic, pramila, jayapal, of, washington,...   \n",
       "\n",
       "                                        no_stopwords  \n",
       "0  [world, antisemitism, speech, felt, resolution...  \n",
       "1  [content, investigate, limit, population, cour...  \n",
       "2  [active, weight, announce, approve, sleep, rec...  \n",
       "3  [medicare, recommends, word, investigate, mone...  \n",
       "4  [world, rape, meaningful, antisemitism, number...  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove stopwords\n",
    "\n",
    "def remove_sw(row):\n",
    "      return list(set(row['lemmatized']).difference(stopwords.words()))\n",
    "\n",
    "df['no_stopwords'] = df.apply(remove_sw,axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e78699d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>cat_label</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>no_stopwords</th>\n",
       "      <th>clean_blob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senate Majority Leader Chuck Schumer accused K...</td>\n",
       "      <td>Politics</td>\n",
       "      <td>[senate, majority, leader, chuck, schumer, acc...</td>\n",
       "      <td>[senate, majority, leader, chuck, schumer, acc...</td>\n",
       "      <td>[world, antisemitism, speech, felt, resolution...</td>\n",
       "      <td>world antisemitism speech felt resolution repu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Panera is being sued again after another custo...</td>\n",
       "      <td>Politics</td>\n",
       "      <td>[panera, is, being, sued, again, after, anothe...</td>\n",
       "      <td>[panera, be, be, sue, again, after, another, c...</td>\n",
       "      <td>[content, investigate, limit, population, cour...</td>\n",
       "      <td>content investigate limit population course tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Drug manufacturer Eli Lilly announced Tuesday ...</td>\n",
       "      <td>Health | Science | Technology</td>\n",
       "      <td>[drug, manufacturer, eli, lilly, announced, tu...</td>\n",
       "      <td>[drug, manufacturer, eli, lilly, announce, tue...</td>\n",
       "      <td>[active, weight, announce, approve, sleep, rec...</td>\n",
       "      <td>active weight announce approve sleep recommend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>As director of the Lymphoma Clinical Research ...</td>\n",
       "      <td>Health | Science | Technology</td>\n",
       "      <td>[as, director, of, the, lymphoma, clinical, re...</td>\n",
       "      <td>[a, director, of, the, lymphoma, clinical, res...</td>\n",
       "      <td>[medicare, recommends, word, investigate, mone...</td>\n",
       "      <td>medicare recommends word investigate money cen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Democratic Rep. Pramila Jayapal of Washington ...</td>\n",
       "      <td>Politics</td>\n",
       "      <td>[democratic, pramila, jayapal, of, washington,...</td>\n",
       "      <td>[democratic, pramila, jayapal, of, washington,...</td>\n",
       "      <td>[world, rape, meaningful, antisemitism, number...</td>\n",
       "      <td>world rape meaningful antisemitism number comm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  Senate Majority Leader Chuck Schumer accused K...   \n",
       "1  Panera is being sued again after another custo...   \n",
       "2  Drug manufacturer Eli Lilly announced Tuesday ...   \n",
       "3  As director of the Lymphoma Clinical Research ...   \n",
       "4  Democratic Rep. Pramila Jayapal of Washington ...   \n",
       "\n",
       "                       cat_label  \\\n",
       "0                       Politics   \n",
       "1                       Politics   \n",
       "2  Health | Science | Technology   \n",
       "3  Health | Science | Technology   \n",
       "4                       Politics   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  [senate, majority, leader, chuck, schumer, acc...   \n",
       "1  [panera, is, being, sued, again, after, anothe...   \n",
       "2  [drug, manufacturer, eli, lilly, announced, tu...   \n",
       "3  [as, director, of, the, lymphoma, clinical, re...   \n",
       "4  [democratic, pramila, jayapal, of, washington,...   \n",
       "\n",
       "                                          lemmatized  \\\n",
       "0  [senate, majority, leader, chuck, schumer, acc...   \n",
       "1  [panera, be, be, sue, again, after, another, c...   \n",
       "2  [drug, manufacturer, eli, lilly, announce, tue...   \n",
       "3  [a, director, of, the, lymphoma, clinical, res...   \n",
       "4  [democratic, pramila, jayapal, of, washington,...   \n",
       "\n",
       "                                        no_stopwords  \\\n",
       "0  [world, antisemitism, speech, felt, resolution...   \n",
       "1  [content, investigate, limit, population, cour...   \n",
       "2  [active, weight, announce, approve, sleep, rec...   \n",
       "3  [medicare, recommends, word, investigate, mone...   \n",
       "4  [world, rape, meaningful, antisemitism, number...   \n",
       "\n",
       "                                          clean_blob  \n",
       "0  world antisemitism speech felt resolution repu...  \n",
       "1  content investigate limit population course tr...  \n",
       "2  active weight announce approve sleep recommend...  \n",
       "3  medicare recommends word investigate money cen...  \n",
       "4  world rape meaningful antisemitism number comm...  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def re_blob(row):\n",
    "      return \" \".join(row['no_stopwords'])\n",
    "\n",
    "df['clean_blob'] = df.apply(re_blob,axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14affa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_vect = CountVectorizer(max_features=7500)\n",
    "# fit creates one entry for each different word seen\n",
    "X = bow_vect.fit_transform(df['clean_blob']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9116b6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('bow_vect.pkl', 'wb') as file:\n",
    "     pickle.dump(bow_vect, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1dd6d76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"cat_label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "704ba3bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.model_selection import train_test_split\\nimport pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a776e5e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Politics                         769\n",
       "Entertainment and Lifestyle      273\n",
       "International News               247\n",
       "Sports                           164\n",
       "Business and Economy              36\n",
       "Health | Science | Technology     28\n",
       "Climate and Environment           20\n",
       "Law and Justice                   19\n",
       "Name: cat_label, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d79b977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.model_selection import train_test_split\\nimport pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train = pd.DataFrame(X_train)\n",
    "y_train = y_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "50941f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.model_selection import train_test_split\\nimport pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.model_selection import train_test_split\\nimport pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "politics = train[train[\"cat_label\"]==\"Politics\"]\n",
    "not_politics = train[train[\"cat_label\"]!=\"Politics\"]\n",
    "\n",
    "politics_under = resample(politics,\n",
    "                   replace=False,\n",
    "                   n_samples=650,\n",
    "                    random_state=0)\n",
    "\n",
    "train_under = pd.concat([politics_under, not_politics])\n",
    "X_train = train_under.drop(\"cat_label\", axis=1)\n",
    "y_train = train_under[\"cat_label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d8fb0985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.model_selection import train_test_split\\nimport pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.model_selection import train_test_split\\nimport pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "health = train[train[\"cat_label\"]==\"Health | Science | Technology\"]\n",
    "not_health = train[train[\"cat_label\"]!=\"Health | Science | Technology\"]\n",
    "\n",
    "health_over = resample(health,\n",
    "                   replace=True,\n",
    "                   n_samples=200,\n",
    "                    random_state=0)\n",
    "\n",
    "train_under = pd.concat([health_over, not_health])\n",
    "X_train = train_under.drop(\"cat_label\", axis=1)\n",
    "y_train = train_under[\"cat_label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d116e35a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.model_selection import train_test_split\\nimport pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.model_selection import train_test_split\\nimport pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "buisness = train[train[\"cat_label\"]==\"Business and Economy\"]\n",
    "not_buisness = train[train[\"cat_label\"]!=\"Business and Economy\"]\n",
    "\n",
    "buisness_over = resample(buisness,\n",
    "                   replace=True,\n",
    "                   n_samples=220,\n",
    "                    random_state=0)\n",
    "\n",
    "train_under = pd.concat([buisness_over, not_buisness])\n",
    "X_train = train_under.drop(\"cat_label\", axis=1)\n",
    "y_train = train_under[\"cat_label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a86a2cad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.model_selection import train_test_split\\nimport pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.model_selection import train_test_split\\nimport pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "clim = train[train[\"cat_label\"]==\"Climate and Environment\"]\n",
    "not_clim = train[train[\"cat_label\"]!=\"Climate and Environment\"]\n",
    "\n",
    "clim_over = resample(clim,\n",
    "                   replace=True,\n",
    "                   n_samples=100,\n",
    "                    random_state=0)\n",
    "\n",
    "train_under = pd.concat([clim_over, not_clim])\n",
    "X_train = train_under.drop(\"cat_label\", axis=1)\n",
    "y_train = train_under[\"cat_label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8384bf88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.model_selection import train_test_split\\nimport pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.model_selection import train_test_split\\nimport pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "law = train[train[\"cat_label\"]==\"Law and Justice\"]\n",
    "not_law = train[train[\"cat_label\"]!=\"Law and Justice\"]\n",
    "\n",
    "law_over = resample(law,\n",
    "                   replace=True,\n",
    "                   n_samples=100,\n",
    "                    random_state=0)\n",
    "\n",
    "train_under = pd.concat([law_over, not_law])\n",
    "X_train = train_under.drop(\"cat_label\", axis=1)\n",
    "y_train = train_under[\"cat_label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "df84de91",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d08ee220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Politics                         650\n",
       "Entertainment and Lifestyle      273\n",
       "International News               247\n",
       "Business and Economy             220\n",
       "Health | Science | Technology    200\n",
       "Sports                           164\n",
       "Law and Justice                  100\n",
       "Climate and Environment          100\n",
       "Name: cat_label, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "29351a42",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m best_model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m      2\u001b[0m y_pred\u001b[38;5;241m=\u001b[39m best_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_model' is not defined"
     ]
    }
   ],
   "source": [
    "best_model.fit(X_train, y_train)\n",
    "y_pred= best_model.predict(X_test)\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "#print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9500523b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LogisticRegression\\nimport pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8020565552699229\n",
      "Classification Report:\n",
      "                                precision    recall  f1-score   support\n",
      "\n",
      "         Business and Economy       0.60      0.33      0.43         9\n",
      "      Climate and Environment       1.00      0.22      0.36         9\n",
      "  Entertainment and Lifestyle       0.73      0.78      0.75        73\n",
      "Health | Science | Technology       0.60      0.50      0.55         6\n",
      "           International News       0.80      0.76      0.78        59\n",
      "              Law and Justice       0.00      0.00      0.00         4\n",
      "                     Politics       0.80      0.88      0.84       182\n",
      "                       Sports       0.98      0.87      0.92        47\n",
      "\n",
      "                     accuracy                           0.80       389\n",
      "                    macro avg       0.69      0.54      0.58       389\n",
      "                 weighted avg       0.80      0.80      0.79       389\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "log = LogisticRegression()\n",
    "\n",
    "log.fit(X_train, y_train)\n",
    "y_pred = log.predict(X_test)\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6d5202e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('cat_model.pkl', 'wb') as file:\n",
    "    pickle.dump(log, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "bfbd2f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8240109140518418\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC()\n",
    "\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred = svc.predict(X_test)\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "#print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6017d602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7776261937244202\n",
      "Classification Report:\n",
      "                                precision    recall  f1-score   support\n",
      "\n",
      "         Business and Economy       1.00      0.08      0.14        13\n",
      "      Climate and Environment       0.67      0.50      0.57         4\n",
      "  Entertainment and Lifestyle       0.86      0.66      0.75       169\n",
      "Health | Science | Technology       0.88      0.33      0.48        21\n",
      "           International News       0.86      0.32      0.47        74\n",
      "              Law and Justice       0.00      0.00      0.00         7\n",
      "                     Politics       0.72      0.96      0.83       377\n",
      "                       Sports       0.98      0.90      0.94        68\n",
      "\n",
      "                     accuracy                           0.78       733\n",
      "                    macro avg       0.75      0.47      0.52       733\n",
      "                 weighted avg       0.80      0.78      0.75       733\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ab8bb2c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LogisticRegression'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "90 fits failed out of a total of 240.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.19863263        nan 0.66636728 0.66636728\n",
      " 0.68659034 0.66636728        nan        nan 0.44008349        nan\n",
      " 0.86173008 0.86173008 0.86143379 0.86113573        nan        nan\n",
      " 0.81028665        nan 0.88046062 0.8807578  0.88700294 0.88224634\n",
      "        nan        nan 0.86351491        nan 0.87867801 0.87838039\n",
      " 0.88492093 0.88046151        nan        nan 0.86083988        nan\n",
      " 0.87748886 0.88046195 0.88373222 0.88075824        nan        nan\n",
      " 0.86916216        nan 0.87808233 0.87927059 0.88343372 0.88284025]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Accuracy: 0.83\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "              'penalty': ['l1', 'l2'],\n",
    "              'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag']}\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(logreg, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "aef52a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Accuracy on Test Set: 0.8308321964529332\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "}\n",
    "\n",
    "# Create an SVC model\n",
    "svc = SVC()\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(svc, param_grid, cv=3, scoring='accuracy')\n",
    "\n",
    "# Fit the model to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Accuracy on Test Set:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c067be02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7694406548431105"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d8a77c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
