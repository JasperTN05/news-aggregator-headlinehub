{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aad5e6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "083be2e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>An Australian police officer has been charged ...</td>\n",
       "      <td>australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Three people have been killed in an auto shop ...</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The trial in the assault and harassment case a...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Soccer is set to trial sin bins at the higher ...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bob Iger, neatly dressed in a gray suit and pr...</td>\n",
       "      <td>media</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7383</th>\n",
       "      <td>Kevin McCarthy has for now lost the House spea...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7384</th>\n",
       "      <td>Michael Duane Zack III, who was convicted of t...</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7385</th>\n",
       "      <td>Seven Starbucks locations across San Francisco...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7386</th>\n",
       "      <td>At least 21 people were killed, including two ...</td>\n",
       "      <td>europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7387</th>\n",
       "      <td>Former President Donald Trump spent the last t...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5162 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text       Category\n",
       "0     An Australian police officer has been charged ...      australia\n",
       "1     Three people have been killed in an auto shop ...             us\n",
       "2     The trial in the assault and harassment case a...  entertainment\n",
       "3     Soccer is set to trial sin bins at the higher ...          sport\n",
       "4     Bob Iger, neatly dressed in a gray suit and pr...          media\n",
       "...                                                 ...            ...\n",
       "7383  Kevin McCarthy has for now lost the House spea...       politics\n",
       "7384  Michael Duane Zack III, who was convicted of t...             us\n",
       "7385  Seven Starbucks locations across San Francisco...       business\n",
       "7386  At least 21 people were killed, including two ...         europe\n",
       "7387  Former President Donald Trump spent the last t...       politics\n",
       "\n",
       "[5162 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./datasets/cat_train.csv\")\n",
    "df = df.drop(\"Unnamed: 0\", axis=1)\n",
    "df.dropna(inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "09c910b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./datasets/all_articles.csv\")\n",
    "data.drop(\"Unnamed: 0\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "29f74b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Politics                         455\n",
       "Entertainment and Lifestyle      156\n",
       "International News                90\n",
       "Sports                            78\n",
       "Health | Science | Technology     24\n",
       "Business and Economy              20\n",
       "Law and Justice                   20\n",
       "Climate and Environment           12\n",
       "Name: cat_label, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna(inplace=True)\n",
    "data = data[data[\"cat_label\"]!= \"Breaking News\"]\n",
    "data[\"cat_label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "02e52c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Category\"] = df[\"Category\"].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f06496aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_categories(x):\n",
    "    category_mapping = {\n",
    "        'International News': ['world',\"ukraine\", 'australia','india', 'china', 'americas', 'middleeast','international','Israel Hamas War', 'africa', 'asia', 'europe'],\n",
    "        'Politics': ['nation' , 'new york', 'Congress','us', 'politics'],\n",
    "        'Business and Economy': ['investing', 'business', 'markets', 'money'],\n",
    "        'Entertainment and Lifestyle': [\"lifestyle\",\"travel\", 'entertainment', 'cars', 'culture', 'food', 'style', 'tech','advice', 'success', 'books', 'cruise ship', 'wellness', 'family', 'life expectancy'],\n",
    "        'Climate and Environment': ['climate','energy' 'climate-environment', 'climate-solutions'],\n",
    "        'Health | Science | Technology': ['health', 'science', 'technology', 'artificial intelligence'],\n",
    "        'Sports': ['sport', 'sports'],\n",
    "        'Law and Justice': ['national-security', 'criminajustice', \"retail theft\", \"financial crimes\", \"crime\",  ],\n",
    "        'del' : [\"weather\" ] \n",
    "    }\n",
    "\n",
    "    categorized_result = {category: [] for category in category_mapping.keys()}\n",
    "    matched_category = None\n",
    "    for main_category, sub_categories in category_mapping.items():\n",
    "        if any(sub_category in x.lower() for sub_category in sub_categories):\n",
    "            matched_category = main_category\n",
    "            break\n",
    "    \n",
    "    return matched_category\n",
    "\n",
    "df[\"cat_label\"] = df[\"Category\"].apply(categorize_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3e0be306",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"cat_label\"]!=\"del\"]\n",
    "df = df[df[\"cat_label\"]!=\"politics\"]\n",
    "df.dropna(inplace=True)\n",
    "data = data[[\"Text\", \"cat_label\"]]\n",
    "df = df[[\"Text\", \"cat_label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7486c085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.concat([data, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "02c3e99b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>cat_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Former President Donald Trump and Florida Gov....</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ashley Renne posted a more than minute-long vi...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beyond Columbia University’s heavy iron gates ...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The recent debate over Beyoncé’s appearance at...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>North Korea has warned any potential interfere...</td>\n",
       "      <td>International News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7383</th>\n",
       "      <td>Kevin McCarthy has for now lost the House spea...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7384</th>\n",
       "      <td>Michael Duane Zack III, who was convicted of t...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7385</th>\n",
       "      <td>Seven Starbucks locations across San Francisco...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7386</th>\n",
       "      <td>At least 21 people were killed, including two ...</td>\n",
       "      <td>International News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7387</th>\n",
       "      <td>Former President Donald Trump spent the last t...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3665 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text           cat_label\n",
       "0     Former President Donald Trump and Florida Gov....            Politics\n",
       "1     Ashley Renne posted a more than minute-long vi...            Politics\n",
       "2     Beyond Columbia University’s heavy iron gates ...            Politics\n",
       "3     The recent debate over Beyoncé’s appearance at...            Politics\n",
       "6     North Korea has warned any potential interfere...  International News\n",
       "...                                                 ...                 ...\n",
       "7383  Kevin McCarthy has for now lost the House spea...            Politics\n",
       "7384  Michael Duane Zack III, who was convicted of t...            Politics\n",
       "7385  Seven Starbucks locations across San Francisco...            Politics\n",
       "7386  At least 21 people were killed, including two ...  International News\n",
       "7387  Former President Donald Trump spent the last t...            Politics\n",
       "\n",
       "[3665 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(keep=\"first\", inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "142c2ebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Politics                         1857\n",
       "Entertainment and Lifestyle       837\n",
       "International News                396\n",
       "Sports                            371\n",
       "Health | Science | Technology     118\n",
       "Business and Economy               43\n",
       "Climate and Environment            22\n",
       "Law and Justice                    21\n",
       "Name: cat_label, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"cat_label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c2946b",
   "metadata": {},
   "source": [
    "## Tokenize etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1ecd437d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk #Natural Language tool kit -- this pacakge is quite a mess. Was poorly design and the documentation is not great\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c7665cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>cat_label</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Former President Donald Trump and Florida Gov....</td>\n",
       "      <td>Politics</td>\n",
       "      <td>[former, president, donald, trump, and, florid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ashley Renne posted a more than minute-long vi...</td>\n",
       "      <td>Politics</td>\n",
       "      <td>[ashley, renne, posted, a, more, than, video, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beyond Columbia University’s heavy iron gates ...</td>\n",
       "      <td>Politics</td>\n",
       "      <td>[beyond, columbia, university, s, heavy, iron,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The recent debate over Beyoncé’s appearance at...</td>\n",
       "      <td>Politics</td>\n",
       "      <td>[the, recent, debate, over, beyoncé, s, appear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>North Korea has warned any potential interfere...</td>\n",
       "      <td>International News</td>\n",
       "      <td>[north, korea, has, warned, any, potential, in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text           cat_label  \\\n",
       "0  Former President Donald Trump and Florida Gov....            Politics   \n",
       "1  Ashley Renne posted a more than minute-long vi...            Politics   \n",
       "2  Beyond Columbia University’s heavy iron gates ...            Politics   \n",
       "3  The recent debate over Beyoncé’s appearance at...            Politics   \n",
       "6  North Korea has warned any potential interfere...  International News   \n",
       "\n",
       "                                           tokenized  \n",
       "0  [former, president, donald, trump, and, florid...  \n",
       "1  [ashley, renne, posted, a, more, than, video, ...  \n",
       "2  [beyond, columbia, university, s, heavy, iron,...  \n",
       "3  [the, recent, debate, over, beyoncé, s, appear...  \n",
       "6  [north, korea, has, warned, any, potential, in...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenizer_and_remove_punctuation(row):\n",
    "    tokens = word_tokenize(row['Text'])\n",
    "    return [word.lower() for word in tokens if word.isalpha()]\n",
    "\n",
    "df['tokenized'] = df.apply(tokenizer_and_remove_punctuation,axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d6609950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word], lang='eng')[0][1][0].upper() # gets first letter of POS categorization\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1453ef70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>cat_label</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Former President Donald Trump and Florida Gov....</td>\n",
       "      <td>Politics</td>\n",
       "      <td>[former, president, donald, trump, and, florid...</td>\n",
       "      <td>[former, president, donald, trump, and, florid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ashley Renne posted a more than minute-long vi...</td>\n",
       "      <td>Politics</td>\n",
       "      <td>[ashley, renne, posted, a, more, than, video, ...</td>\n",
       "      <td>[ashley, renne, post, a, more, than, video, to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beyond Columbia University’s heavy iron gates ...</td>\n",
       "      <td>Politics</td>\n",
       "      <td>[beyond, columbia, university, s, heavy, iron,...</td>\n",
       "      <td>[beyond, columbia, university, s, heavy, iron,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The recent debate over Beyoncé’s appearance at...</td>\n",
       "      <td>Politics</td>\n",
       "      <td>[the, recent, debate, over, beyoncé, s, appear...</td>\n",
       "      <td>[the, recent, debate, over, beyoncé, s, appear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>North Korea has warned any potential interfere...</td>\n",
       "      <td>International News</td>\n",
       "      <td>[north, korea, has, warned, any, potential, in...</td>\n",
       "      <td>[north, korea, have, warn, any, potential, int...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text           cat_label  \\\n",
       "0  Former President Donald Trump and Florida Gov....            Politics   \n",
       "1  Ashley Renne posted a more than minute-long vi...            Politics   \n",
       "2  Beyond Columbia University’s heavy iron gates ...            Politics   \n",
       "3  The recent debate over Beyoncé’s appearance at...            Politics   \n",
       "6  North Korea has warned any potential interfere...  International News   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  [former, president, donald, trump, and, florid...   \n",
       "1  [ashley, renne, posted, a, more, than, video, ...   \n",
       "2  [beyond, columbia, university, s, heavy, iron,...   \n",
       "3  [the, recent, debate, over, beyoncé, s, appear...   \n",
       "6  [north, korea, has, warned, any, potential, in...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  [former, president, donald, trump, and, florid...  \n",
       "1  [ashley, renne, post, a, more, than, video, to...  \n",
       "2  [beyond, columbia, university, s, heavy, iron,...  \n",
       "3  [the, recent, debate, over, beyoncé, s, appear...  \n",
       "6  [north, korea, have, warn, any, potential, int...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lemmatizer_with_pos(row):\n",
    "      return [lemmatizer.lemmatize(word,get_wordnet_pos(word)) for word in row['tokenized']]\n",
    "\n",
    "df['lemmatized'] = df.apply(lemmatizer_with_pos,axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "72b01c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>cat_label</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>no_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Former President Donald Trump and Florida Gov....</td>\n",
       "      <td>Politics</td>\n",
       "      <td>[former, president, donald, trump, and, florid...</td>\n",
       "      <td>[former, president, donald, trump, and, florid...</td>\n",
       "      <td>[event, state, recent, south, immigration, pop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ashley Renne posted a more than minute-long vi...</td>\n",
       "      <td>Politics</td>\n",
       "      <td>[ashley, renne, posted, a, more, than, video, ...</td>\n",
       "      <td>[ashley, renne, post, a, more, than, video, to...</td>\n",
       "      <td>[access, dozen, effective, instagram, event, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beyond Columbia University’s heavy iron gates ...</td>\n",
       "      <td>Politics</td>\n",
       "      <td>[beyond, columbia, university, s, heavy, iron,...</td>\n",
       "      <td>[beyond, columbia, university, s, heavy, iron,...</td>\n",
       "      <td>[problem, harassment, channel, applicable, ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The recent debate over Beyoncé’s appearance at...</td>\n",
       "      <td>Politics</td>\n",
       "      <td>[the, recent, debate, over, beyoncé, s, appear...</td>\n",
       "      <td>[the, recent, debate, over, beyoncé, s, appear...</td>\n",
       "      <td>[internalize, instagram, mom, event, recent, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>North Korea has warned any potential interfere...</td>\n",
       "      <td>International News</td>\n",
       "      <td>[north, korea, has, warned, any, potential, in...</td>\n",
       "      <td>[north, korea, have, warn, any, potential, int...</td>\n",
       "      <td>[country, state, south, defense, destroy, veri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text           cat_label  \\\n",
       "0  Former President Donald Trump and Florida Gov....            Politics   \n",
       "1  Ashley Renne posted a more than minute-long vi...            Politics   \n",
       "2  Beyond Columbia University’s heavy iron gates ...            Politics   \n",
       "3  The recent debate over Beyoncé’s appearance at...            Politics   \n",
       "6  North Korea has warned any potential interfere...  International News   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  [former, president, donald, trump, and, florid...   \n",
       "1  [ashley, renne, posted, a, more, than, video, ...   \n",
       "2  [beyond, columbia, university, s, heavy, iron,...   \n",
       "3  [the, recent, debate, over, beyoncé, s, appear...   \n",
       "6  [north, korea, has, warned, any, potential, in...   \n",
       "\n",
       "                                          lemmatized  \\\n",
       "0  [former, president, donald, trump, and, florid...   \n",
       "1  [ashley, renne, post, a, more, than, video, to...   \n",
       "2  [beyond, columbia, university, s, heavy, iron,...   \n",
       "3  [the, recent, debate, over, beyoncé, s, appear...   \n",
       "6  [north, korea, have, warn, any, potential, int...   \n",
       "\n",
       "                                        no_stopwords  \n",
       "0  [event, state, recent, south, immigration, pop...  \n",
       "1  [access, dozen, effective, instagram, event, c...  \n",
       "2  [problem, harassment, channel, applicable, ins...  \n",
       "3  [internalize, instagram, mom, event, recent, w...  \n",
       "6  [country, state, south, defense, destroy, veri...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove stopwords\n",
    "\n",
    "def remove_sw(row):\n",
    "      return list(set(row['lemmatized']).difference(stopwords.words()))\n",
    "\n",
    "df['no_stopwords'] = df.apply(remove_sw,axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e78699d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>cat_label</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>no_stopwords</th>\n",
       "      <th>clean_blob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Former President Donald Trump and Florida Gov....</td>\n",
       "      <td>Politics</td>\n",
       "      <td>[former, president, donald, trump, and, florid...</td>\n",
       "      <td>[former, president, donald, trump, and, florid...</td>\n",
       "      <td>[event, state, recent, south, immigration, pop...</td>\n",
       "      <td>event state recent south immigration popular g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ashley Renne posted a more than minute-long vi...</td>\n",
       "      <td>Politics</td>\n",
       "      <td>[ashley, renne, posted, a, more, than, video, ...</td>\n",
       "      <td>[ashley, renne, post, a, more, than, video, to...</td>\n",
       "      <td>[access, dozen, effective, instagram, event, c...</td>\n",
       "      <td>access dozen effective instagram event country...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beyond Columbia University’s heavy iron gates ...</td>\n",
       "      <td>Politics</td>\n",
       "      <td>[beyond, columbia, university, s, heavy, iron,...</td>\n",
       "      <td>[beyond, columbia, university, s, heavy, iron,...</td>\n",
       "      <td>[problem, harassment, channel, applicable, ins...</td>\n",
       "      <td>problem harassment channel applicable instagra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The recent debate over Beyoncé’s appearance at...</td>\n",
       "      <td>Politics</td>\n",
       "      <td>[the, recent, debate, over, beyoncé, s, appear...</td>\n",
       "      <td>[the, recent, debate, over, beyoncé, s, appear...</td>\n",
       "      <td>[internalize, instagram, mom, event, recent, w...</td>\n",
       "      <td>internalize instagram mom event recent work pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>North Korea has warned any potential interfere...</td>\n",
       "      <td>International News</td>\n",
       "      <td>[north, korea, has, warned, any, potential, in...</td>\n",
       "      <td>[north, korea, have, warn, any, potential, int...</td>\n",
       "      <td>[country, state, south, defense, destroy, veri...</td>\n",
       "      <td>country state south defense destroy verify dem...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text           cat_label  \\\n",
       "0  Former President Donald Trump and Florida Gov....            Politics   \n",
       "1  Ashley Renne posted a more than minute-long vi...            Politics   \n",
       "2  Beyond Columbia University’s heavy iron gates ...            Politics   \n",
       "3  The recent debate over Beyoncé’s appearance at...            Politics   \n",
       "6  North Korea has warned any potential interfere...  International News   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  [former, president, donald, trump, and, florid...   \n",
       "1  [ashley, renne, posted, a, more, than, video, ...   \n",
       "2  [beyond, columbia, university, s, heavy, iron,...   \n",
       "3  [the, recent, debate, over, beyoncé, s, appear...   \n",
       "6  [north, korea, has, warned, any, potential, in...   \n",
       "\n",
       "                                          lemmatized  \\\n",
       "0  [former, president, donald, trump, and, florid...   \n",
       "1  [ashley, renne, post, a, more, than, video, to...   \n",
       "2  [beyond, columbia, university, s, heavy, iron,...   \n",
       "3  [the, recent, debate, over, beyoncé, s, appear...   \n",
       "6  [north, korea, have, warn, any, potential, int...   \n",
       "\n",
       "                                        no_stopwords  \\\n",
       "0  [event, state, recent, south, immigration, pop...   \n",
       "1  [access, dozen, effective, instagram, event, c...   \n",
       "2  [problem, harassment, channel, applicable, ins...   \n",
       "3  [internalize, instagram, mom, event, recent, w...   \n",
       "6  [country, state, south, defense, destroy, veri...   \n",
       "\n",
       "                                          clean_blob  \n",
       "0  event state recent south immigration popular g...  \n",
       "1  access dozen effective instagram event country...  \n",
       "2  problem harassment channel applicable instagra...  \n",
       "3  internalize instagram mom event recent work pa...  \n",
       "6  country state south defense destroy verify dem...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def re_blob(row):\n",
    "      return \" \".join(row['no_stopwords'])\n",
    "\n",
    "df['clean_blob'] = df.apply(re_blob,axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "14affa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_vect = CountVectorizer(max_features=7500)\n",
    "# fit creates one entry for each different word seen\n",
    "X = bow_vect.fit_transform(df['clean_blob']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9116b6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('bow_vect.pkl', 'wb') as file:\n",
    "     pickle.dump(bow_vect, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1dd6d76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"cat_label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "704ba3bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LogisticRegression'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a776e5e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Politics                         1480\n",
       "Entertainment and Lifestyle       668\n",
       "International News                322\n",
       "Sports                            303\n",
       "Health | Science | Technology      97\n",
       "Business and Economy               30\n",
       "Climate and Environment            18\n",
       "Law and Justice                    14\n",
       "Name: cat_label, dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6d79b977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LogisticRegression'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train = pd.DataFrame(X_train)\n",
    "y_train = y_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "50941f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LogisticRegression'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LogisticRegression'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "politics = train[train[\"cat_label\"]==\"Politics\"]\n",
    "not_politics = train[train[\"cat_label\"]!=\"Politics\"]\n",
    "\n",
    "politics_under = resample(politics,\n",
    "                   replace=False,\n",
    "                   n_samples=800,\n",
    "                    random_state=0)\n",
    "\n",
    "train_under = pd.concat([politics_under, not_politics])\n",
    "X_train_under = train_under.drop(\"cat_label\", axis=1)\n",
    "y_train_under = train_under[\"cat_label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d8fb0985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LogisticRegression'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LogisticRegression'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "health = train[train[\"cat_label\"]==\"Health | Science | Technology\"]\n",
    "not_health = train[train[\"cat_label\"]!=\"Health | Science | Technology\"]\n",
    "\n",
    "health_over = resample(health,\n",
    "                   replace=True,\n",
    "                   n_samples=200,\n",
    "                    random_state=0)\n",
    "\n",
    "train_under = pd.concat([health_over, not_health])\n",
    "X_train = train_under.drop(\"cat_label\", axis=1)\n",
    "y_train = train_under[\"cat_label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d116e35a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LogisticRegression'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LogisticRegression'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "buisness = train[train[\"cat_label\"]==\"Business and Economy\"]\n",
    "not_buisness = train[train[\"cat_label\"]!=\"Business and Economy\"]\n",
    "\n",
    "buisness_over = resample(buisness,\n",
    "                   replace=True,\n",
    "                   n_samples=220,\n",
    "                    random_state=0)\n",
    "\n",
    "train_under = pd.concat([buisness_over, not_buisness])\n",
    "X_train = train_under.drop(\"cat_label\", axis=1)\n",
    "y_train = train_under[\"cat_label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a86a2cad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LogisticRegression'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LogisticRegression'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "clim = train[train[\"cat_label\"]==\"Climate and Environment\"]\n",
    "not_clim = train[train[\"cat_label\"]!=\"Climate and Environment\"]\n",
    "\n",
    "clim_over = resample(clim,\n",
    "                   replace=True,\n",
    "                   n_samples=100,\n",
    "                    random_state=0)\n",
    "\n",
    "train_under = pd.concat([clim_over, not_clim])\n",
    "X_train = train_under.drop(\"cat_label\", axis=1)\n",
    "y_train = train_under[\"cat_label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8384bf88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LogisticRegression'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LogisticRegression'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "law = train[train[\"cat_label\"]==\"Law and Justice\"]\n",
    "not_law = train[train[\"cat_label\"]!=\"Law and Justice\"]\n",
    "\n",
    "law_over = resample(law,\n",
    "                   replace=True,\n",
    "                   n_samples=70,\n",
    "                    random_state=0)\n",
    "\n",
    "train_under = pd.concat([law_over, not_law])\n",
    "X_train = train_under.drop(\"cat_label\", axis=1)\n",
    "y_train = train_under[\"cat_label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "df84de91",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "29351a42",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m best_model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m      2\u001b[0m y_pred\u001b[38;5;241m=\u001b[39m best_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_model' is not defined"
     ]
    }
   ],
   "source": [
    "best_model.fit(X_train, y_train)\n",
    "y_pred= best_model.predict(X_test)\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "#print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9500523b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LogisticRegression'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8308321964529332\n",
      "Classification Report:\n",
      "                                precision    recall  f1-score   support\n",
      "\n",
      "         Business and Economy       0.43      0.23      0.30        13\n",
      "      Climate and Environment       0.67      0.50      0.57         4\n",
      "  Entertainment and Lifestyle       0.83      0.79      0.81       169\n",
      "Health | Science | Technology       0.68      0.71      0.70        21\n",
      "           International News       0.78      0.73      0.76        74\n",
      "              Law and Justice       1.00      0.14      0.25         7\n",
      "                     Politics       0.83      0.90      0.86       377\n",
      "                       Sports       0.97      0.90      0.93        68\n",
      "\n",
      "                     accuracy                           0.83       733\n",
      "                    macro avg       0.77      0.61      0.65       733\n",
      "                 weighted avg       0.83      0.83      0.83       733\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "log = LogisticRegression()\n",
    "\n",
    "log.fit(X_train, y_train)\n",
    "y_pred = log.predict(X_test)\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6d5202e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('cat_model.pkl', 'wb') as file:\n",
    "    pickle.dump(log, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "bfbd2f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8240109140518418\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC()\n",
    "\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred = svc.predict(X_test)\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "#print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6017d602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7776261937244202\n",
      "Classification Report:\n",
      "                                precision    recall  f1-score   support\n",
      "\n",
      "         Business and Economy       1.00      0.08      0.14        13\n",
      "      Climate and Environment       0.67      0.50      0.57         4\n",
      "  Entertainment and Lifestyle       0.86      0.66      0.75       169\n",
      "Health | Science | Technology       0.88      0.33      0.48        21\n",
      "           International News       0.86      0.32      0.47        74\n",
      "              Law and Justice       0.00      0.00      0.00         7\n",
      "                     Politics       0.72      0.96      0.83       377\n",
      "                       Sports       0.98      0.90      0.94        68\n",
      "\n",
      "                     accuracy                           0.78       733\n",
      "                    macro avg       0.75      0.47      0.52       733\n",
      "                 weighted avg       0.80      0.78      0.75       733\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ab8bb2c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LogisticRegression'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "90 fits failed out of a total of 240.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Jacob\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.19863263        nan 0.66636728 0.66636728\n",
      " 0.68659034 0.66636728        nan        nan 0.44008349        nan\n",
      " 0.86173008 0.86173008 0.86143379 0.86113573        nan        nan\n",
      " 0.81028665        nan 0.88046062 0.8807578  0.88700294 0.88224634\n",
      "        nan        nan 0.86351491        nan 0.87867801 0.87838039\n",
      " 0.88492093 0.88046151        nan        nan 0.86083988        nan\n",
      " 0.87748886 0.88046195 0.88373222 0.88075824        nan        nan\n",
      " 0.86916216        nan 0.87808233 0.87927059 0.88343372 0.88284025]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Accuracy: 0.83\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "              'penalty': ['l1', 'l2'],\n",
    "              'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag']}\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(logreg, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "aef52a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Accuracy on Test Set: 0.8308321964529332\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "}\n",
    "\n",
    "# Create an SVC model\n",
    "svc = SVC()\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(svc, param_grid, cv=3, scoring='accuracy')\n",
    "\n",
    "# Fit the model to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Accuracy on Test Set:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c067be02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7694406548431105"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d8a77c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
